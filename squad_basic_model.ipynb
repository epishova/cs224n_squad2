{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Tensorflow neural model for question answering (SQuAD2)</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>This notebook is based on the <a href=\"http://web.stanford.edu/class/cs224n/\">CS224n class</a>. The notebook implements the neural baseline model in Tensorflow as described in the class <a href=\"http://web.stanford.edu/class/cs224n/project/default-final-project-handout-squad-track.pdf\">final project</a> (IID SQuAD track). The difference is that the CS224n model is implemented in PyTorch, and here you can see how to build the same neural network but in Tensorflow.</p> \n",
    "\n",
    "<p>The implementation follows neural design described in Section 4 of the project write up. To prepare and preprocess the data run setup.py as described in Section 2.2.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88714, 300)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_path = './data/word_emb.json'\n",
    "with open(emb_path) as f:\n",
    "    embedding_matrix = json.load(f)\n",
    "embedding_matrix = np.asarray(embedding_matrix, dtype=np.float32)\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001 # \"Learning rate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100 # \"Batch size to use\"\n",
    "dropout = 0 # 1-keep_prob\n",
    "context_len = 400 # \"The maximum context length of your model\"\n",
    "question_len = 50 # \"The maximum question length of your model\"\n",
    "(VOCAB_SIZE, embedding_size) = embedding_matrix.shape\n",
    "hidden_size = 200 # \"Size of the hidden states\"\n",
    "buffer_size = 10000\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Build the model as shown below. Layers are names in the same way as in CS224n PyTorch model in qa_model.py</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = layers.Input(shape=(context_len, ), name='context')\n",
    "question = layers.Input(shape=(question_len, ), name='question')\n",
    "\n",
    "context_embs = layers.Embedding(input_dim=VOCAB_SIZE,\n",
    "                            output_dim=embedding_size,\n",
    "                            weights=[embedding_matrix],\n",
    "                            trainable=False)(context)\n",
    "qn_embs = layers.Embedding(input_dim=VOCAB_SIZE,\n",
    "                            output_dim=embedding_size,\n",
    "                            weights=[embedding_matrix],\n",
    "                            trainable=False)(question)\n",
    "\n",
    "masking_layer = layers.Masking()\n",
    "masked_context_embs = masking_layer(context_embs)\n",
    "masked_qn_embs = masking_layer(qn_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_layer = layers.GRU(hidden_size, dropout=dropout, return_sequences=True) \n",
    "backward_layer = layers.GRU(hidden_size, dropout=dropout, return_sequences=True, go_backwards=True)\n",
    "bidirect_gru = layers.Bidirectional(forward_layer, \n",
    "                                    backward_layer=backward_layer)\n",
    "context_hiddens = bidirect_gru(masked_context_embs)\n",
    "question_hiddens = bidirect_gru(masked_qn_embs)\n",
    "\n",
    "attn_output = layers.Attention()([context_hiddens, question_hiddens])\n",
    "attn_output = layers.Dropout(dropout)(attn_output)\n",
    "blended_reps = layers.concatenate([context_hiddens, attn_output], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended_reps_final = layers.Dense(units=hidden_size,\n",
    "                                  activation='relu')(blended_reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(3,) dtype=int32 inferred_value=[None, 400, 400] (created by layer 'tf.compat.v1.shape')>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape(context_hiddens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_start = layers.Dense(units=1, activation=None)(blended_reps_final)\n",
    "logits_start = tf.squeeze(logits_start, axis=[2])\n",
    "prob_dist_start = layers.Softmax(axis=1, name = 'tf_op_layer_start')(logits_start)\n",
    "\n",
    "logits_end = layers.Dense(units=1, activation=None)(blended_reps_final)\n",
    "logits_end = tf.squeeze(logits_end, axis=[2]) \n",
    "prob_dist_end = layers.Softmax(axis=1, name = 'tf_op_layer_end')(logits_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Model(inputs=[context, question], outputs=[prob_dist_start, prob_dist_end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['SparseCategoricalAccuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "context (InputLayer)            [(None, 400)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "question (InputLayer)           [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 400, 300)     26614200    context[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 50, 300)      26614200    question[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "masking (Masking)               multiple             0           embedding[0][0]                  \n",
      "                                                                 embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   multiple             602400      masking[0][0]                    \n",
      "                                                                 masking[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 400, 400)     0           bidirectional[0][0]              \n",
      "                                                                 bidirectional[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 400, 400)     0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 400, 800)     0           bidirectional[0][0]              \n",
      "                                                                 dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 400, 200)     160200      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 400, 1)       201         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 400, 1)       201         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze_8 (TFOpLam (None, 400)          0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze_9 (TFOpLam (None, 400)          0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_start (Softmax)     (None, 400)          0           tf.compat.v1.squeeze_8[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_end (Softmax)       (None, 400)          0           tf.compat.v1.squeeze_9[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 53,991,402\n",
      "Trainable params: 763,002\n",
      "Non-trainable params: 53,228,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Load train, dev, and test datasets:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(npz_name, shuffle=False):\n",
    "    npz = np.load(npz_name)\n",
    "    npz_y1s = [context_len-1 if y < 0 else y for y in npz['y1s']]\n",
    "    npz_y2s = [context_len-1 if y < 0 else y for y in npz['y2s']]\n",
    "    context_ds = tf.data.Dataset.from_tensor_slices(npz['context_idxs']) \n",
    "    ques_ds = tf.data.Dataset.from_tensor_slices(npz['ques_idxs']) \n",
    "    start_label = tf.data.Dataset.from_tensor_slices(npz_y1s) \n",
    "    end_label = tf.data.Dataset.from_tensor_slices(npz_y2s) \n",
    "    dataset = tf.data.Dataset.zip(({'context': context_ds, 'question': ques_ds}, \n",
    "                                   {'tf_op_layer_start': start_label, 'tf_op_layer_end': end_label}))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size).batch(batch_size)\n",
    "    else:\n",
    "        dataset = dataset.batch(batch_size)\n",
    "    return dataset\n",
    "    \n",
    "npz_train = './data/train.npz'\n",
    "npz_dev = './data/dev.npz'\n",
    "npz_test = './data/test.npz'\n",
    "\n",
    "train_dataset = load_dataset(npz_train, shuffle=True)\n",
    "dev_dataset = load_dataset(npz_dev)\n",
    "test_dataset = load_dataset(npz_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Set up checkpoints and logs:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = 'training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_best_model.h5\")\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=False,\n",
    "    save_best_only=True)\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1300/1300 [==============================] - 3735s 3s/step - loss: 11.6343 - tf_op_layer_start_loss: 5.8249 - tf_op_layer_end_loss: 5.8094 - tf_op_layer_start_sparse_categorical_accuracy: 0.1740 - tf_op_layer_end_sparse_categorical_accuracy: 0.1910 - val_loss: 11.7266 - val_tf_op_layer_start_loss: 5.8724 - val_tf_op_layer_end_loss: 5.8542 - val_tf_op_layer_start_sparse_categorical_accuracy: 0.1400 - val_tf_op_layer_end_sparse_categorical_accuracy: 0.1500\n",
      "Epoch 2/2\n",
      "1300/1300 [==============================] - 4046s 3s/step - loss: 11.6136 - tf_op_layer_start_loss: 5.8151 - tf_op_layer_end_loss: 5.7984 - tf_op_layer_start_sparse_categorical_accuracy: 0.1844 - tf_op_layer_end_sparse_categorical_accuracy: 0.2011 - val_loss: 11.7208 - val_tf_op_layer_start_loss: 5.8713 - val_tf_op_layer_end_loss: 5.8495 - val_tf_op_layer_start_sparse_categorical_accuracy: 0.1400 - val_tf_op_layer_end_sparse_categorical_accuracy: 0.1500\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset,\n",
    "                    epochs=num_epochs,\n",
    "                    callbacks=[checkpoint_callback, tensorboard_callback],\n",
    "                    validation_data=dev_dataset,\n",
    "                    validation_steps=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>After six training epochs we check the results and compute predictions. Variable prediction is a list of two arrays. Each array is of (# of test examples , context_len) shape. The first array contains predictions for the start position of each answer; the second array contains predictions for the end position of each answer.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The model predicts softmax values for each position in the context. So, we need to take argmax to get the post probable position:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_start = tf.math.argmax(predictions[0], axis=1)\n",
    "pred_end = tf.math.argmax(predictions[1], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Let’s have a look at the predictions for the first 20 test examples and compare those with the test labels:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 34  21  55  65 127 140 140 140 140 176 103  40 252 252 252 252 252  63\n",
      "  57  68]\n",
      "[ 34  21  55  65 127 399 399 399 399 176 103  40 399 399 399 399 399  63\n",
      "  57 399]\n"
     ]
    }
   ],
   "source": [
    "print(tf.slice(pred_start, [0], [20]).numpy())\n",
    "for ex in test_dataset.take(1):\n",
    "    print(ex[1]['tf_op_layer_start'].numpy()[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 34  24  59  65 127 140 140 140 140 178 104  40 252 252 252 252 252  65\n",
      "  58  68]\n",
      "[ 34  24  59  65 127 399 399 399 399 178 104  40 399 399 399 399 399  65\n",
      "  58 399]\n"
     ]
    }
   ],
   "source": [
    "print(tf.slice(pred_end, [0], [20]).numpy())\n",
    "for ex in test_dataset.take(1):\n",
    "    print(ex[1]['tf_op_layer_end'].numpy()[:20])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join('./training_checkpoints', 'save_best_model.h5')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
